{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feccc476",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:æ¸¸æ²›èŠ¸\n",
    "\n",
    "Student ID:F74111097\n",
    "\n",
    "GitHub ID:lala040221\n",
    "\n",
    "Kaggle name:lalala221\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/final_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a7daf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4372660",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9725711f",
   "metadata": {},
   "source": [
    "#  Competition Report â€“ Emotion Recognition on Twitter\n",
    "\n",
    "## 1. Introduction\n",
    "æœ¬æ¬¡æ¯”è³½çš„ä»»å‹™æ˜¯åˆ©ç”¨ Twitter æ–‡æœ¬é€²è¡Œæƒ…ç·’åˆ†é¡ã€‚è³‡æ–™åŒ…å«æ¨æ–‡å…§å®¹èˆ‡ 6 ç¨®æƒ…ç·’æ¨™ç±¤ã€‚æˆ‘æ¡ç”¨å‚³çµ± NLP ç‰¹å¾µï¼ˆTF-IDFï¼‰æ­é…å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œæ¯”è¼ƒï¼Œä¸¦ä»¥ GridSearchCV é€²è¡Œåƒæ•¸æœå°‹å¾Œï¼Œä½¿ç”¨æœ€ä½³æ¨¡å‹ç”¢ç”Ÿ Kaggle submissionã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "æˆ‘å°åŸå§‹æ¨æ–‡é€²è¡Œä»¥ä¸‹å‰è™•ç†ï¼Œç›®çš„æ˜¯æ¸…ç†å™ªéŸ³ä¸¦æå‡å‘é‡åŒ–æ•ˆæœï¼š\n",
    "\n",
    "- ç§»é™¤ URLã€@userã€ç‰¹æ®Šç¬¦è™Ÿã€HTML tag  \n",
    "- ç§»é™¤éå¤šç©ºç™½èˆ‡éæ–‡å­—å­—å…ƒ  \n",
    "- è½‰ç‚ºå°å¯«ï¼ˆlowercaseï¼‰  \n",
    "- æ¸…æ´—å¾Œçš„æ–‡å­—å­˜å…¥ `clean_text` æ¬„ä½  \n",
    "\n",
    "æ­¤è™•ç†æµç¨‹è®“ TF-IDF ç‰¹å¾µæ›´ç©©å®šï¼Œé™ä½é«˜é »å™ªéŸ³è©çš„å¹²æ“¾ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Feature Engineering\n",
    "\n",
    "### 3.1 Hybrid TF-IDFï¼ˆword-level + char-levelï¼‰\n",
    "æˆ‘è¨­è¨ˆ `build_vectorizer()` å‡½å¼ï¼ŒåŒæ™‚ç”¢ç”Ÿï¼š\n",
    "\n",
    "- **word-level TF-IDF**  \n",
    "  - n-gram: (1,1) æˆ– (1,2)  \n",
    "  - ç”¨æ–¼æ•æ‰èªæ„èˆ‡å¦å®šé—œä¿‚ï¼ˆå¦‚ â€œnot happyâ€ï¼‰\n",
    "\n",
    "- **char-level TF-IDF**  \n",
    "  - n-gram: (2,4) æˆ– (3,5)  \n",
    "  - ç‰¹åˆ¥é©åˆ noisy textï¼ˆå¦‚é‡è¤‡å­—æ¯ã€æ‹¼éŒ¯å­—ã€å¼·èª¿ç¬¦è™Ÿï¼‰\n",
    "\n",
    "ä½¿ç”¨ `FeatureUnion` å°‡å…©ç¨®ç‰¹å¾µçµåˆï¼Œæ•ˆæœæ˜é¡¯æ¯”å–®ä¸€å‘é‡å™¨æ›´ä½³ã€‚\n",
    "\n",
    "### (Bonus Insight)\n",
    "- char-level æå‡äº† minority classes çš„ recallã€‚  \n",
    "- (1,2) çš„ word n-gram æ˜é¡¯æ¯”å–®ç¨ unigram æœ‰æ›´å¥½çš„ macro F1ã€‚  \n",
    "- sublinear TF (log-scaling) å¯ä»¥ç©©å®š decision boundaryã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Model Development\n",
    "\n",
    "### 4.1 Base Modelsï¼ˆåˆæ­¥æ¯”è¼ƒï¼‰\n",
    "æˆ‘æ¸¬è©¦äº†å¤šç¨®æ¨¡å‹ï¼š\n",
    "\n",
    "- Logistic Regression  \n",
    "- LinearSVC  \n",
    "- Random Forest  \n",
    "-ï¼ˆé¡å¤–å˜—è©¦ï¼‰Calibrated SVCã€Stackingï¼ˆSVC + LR + RFï¼‰  \n",
    "\n",
    "åœ¨åˆæ­¥ cross-validation ä¸­ï¼š\n",
    "\n",
    "- **LinearSVC è¡¨ç¾æœ€ä½³ä¸”æœ€ç©©å®š**\n",
    "- Logistic Regression æ¬¡ä½³  \n",
    "- Random Forest åœ¨é«˜ç¶­æ–‡å­—ç‰¹å¾µä¸­æ˜é¡¯ underfit  \n",
    "\n",
    "å› æ­¤å¾ŒçºŒæ¡ç”¨ LinearSVC åšä¸»è¦ tuningã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Hyperparameter Tuning (GridSearchCV)\n",
    "\n",
    "æˆ‘ä½¿ç”¨ GridSearchCV å° TF-IDF èˆ‡ SVC é€²è¡Œæ›´å®Œæ•´çš„åƒæ•¸æœå°‹ï¼Œæœå°‹ç©ºé–“åŒ…æ‹¬ï¼š\n",
    "\n",
    "### 5.1 Word-level\n",
    "- `vec__word__ngram_range`: (1,1), (1,2)  \n",
    "- `vec__word__max_features`: 30k, 60k  \n",
    "\n",
    "### 5.2 Char-level\n",
    "- `vec__char__ngram_range`: (2,4), (3,5)  \n",
    "- `vec__char__max_features`: 20k, 40k  \n",
    "\n",
    "### 5.3 SVC\n",
    "- `clf__C`: 0.1, 0.5, 1.0, 2.0  \n",
    "\n",
    "ä½¿ç”¨ `f1_macro` ä½œç‚º scoringï¼Œ5-fold StratifiedKFoldã€‚\n",
    "\n",
    "**æœ€ä½³åƒæ•¸ï¼ˆæ‘˜è¦ï¼‰ï¼š**  \n",
    "- word n-gram = (1,2)  \n",
    "- char n-gram = (3,5)  \n",
    "- åˆé©çš„ max_featuresï¼ˆ60k word, 40k charï¼‰  \n",
    "- C â‰ˆ 1.0â€“2.0 æœ€ä½³  \n",
    "\n",
    "GridSearch æ‰¾åˆ°æœ€ä½³æ¨¡å‹å¾Œï¼Œæˆ‘ä½¿ç”¨ `best_estimator_` é‡æ–°è¨“ç·´ä¸¦ç”¢ç”Ÿ Kaggle æäº¤æª”ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Additional Experimentsï¼ˆBonusï¼‰\n",
    "\n",
    "### 6.1 Model Diagnostics\n",
    "æˆ‘é€²è¡Œä»¥ä¸‹åˆ†æå”åŠ©ç†è§£èª¤åˆ¤æƒ…æ³ï¼š\n",
    "\n",
    "- cross_val_predict çš„åˆ†é¡å ±å‘Š  \n",
    "- confusion matrixï¼ˆè§€å¯Ÿå“ªäº›æƒ…ç·’äº’ç›¸è¢«æ··æ·†ï¼‰  \n",
    "- æ¯”è¼ƒ CV vs full-train çš„é æ¸¬åˆ†ä½ˆ  \n",
    "\n",
    "é€™äº›åˆ†æå”åŠ©æª¢æŸ¥æ¨¡å‹æ˜¯å¦åå‘æŸäº›é¡åˆ¥èˆ‡æ˜¯å¦å­˜åœ¨ overfittingã€‚\n",
    "\n",
    "### 6.2 Stacking Ensembleï¼ˆSVC + LR + RFï¼‰\n",
    "æˆ‘å¯¦ä½œäº†å®Œæ•´ stacking pipelineï¼š\n",
    "\n",
    "- ä½¿ç”¨ 5-fold OOF probability ç”¢ç”Ÿ meta-features  \n",
    "- Meta-model = multinomial Logistic Regression  \n",
    "\n",
    "çµæœç•¥ä½æ–¼æœ€ä½³ GridSearch SVCï¼Œå› æ­¤æœªä½œç‚ºæœ€çµ‚æäº¤ï¼Œä½†å¾ä¸­å­¸åˆ°æ¨¡å‹äº’è£œæ€§èˆ‡ calibration çš„æ•ˆæœã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Results\n",
    "\n",
    "- æœ€çµ‚æ¡ç”¨ **GridSearchCV ä¹‹æœ€ä½³ SVC æ¨¡å‹**  \n",
    "- ä½¿ç”¨ TF-IDF (word + char) + æœ€ä½³åƒæ•¸ç”¢ç”Ÿ submission  \n",
    "- Kaggle Private Leaderboard æ’åï¼š![pic_ranking.png](./pics/final_result.png) \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Insights & Conclusion\n",
    "\n",
    "- word + char çš„ hybrid TF-IDF å° noisy tweet è¡¨ç¾æœ€ä½³  \n",
    "- é©åº¦æé«˜ max_features æå‡æ¨¡å‹èƒ½åŠ›ï¼Œä½†éœ€è¦ GridSearch æ‰¾å¹³è¡¡  \n",
    "- LinearSVC åœ¨æœ¬ç«¶è³½ä¸­æœ€ç©©å®šã€æœ€æœ‰æ•ˆ  \n",
    "- stacking èˆ‡ calibration èƒ½æå‡ç†è§£ä½†ä¸ä¸€å®šæå‡ leaderboard æˆç¸¾  \n",
    "- è‹¥æœ‰æ›´å¤šæ™‚é–“ï¼Œæˆ‘æœƒå˜—è©¦ï¼š  \n",
    "  - ä½¿ç”¨ RoBERTa-base / BERT fine-tuning  \n",
    "  - åš class-balanced sampling æˆ– focal loss  \n",
    "  - æ›´å¤§ n-gram æœå°‹\n",
    "\n",
    "æœ¬æ¬¡æ¨¡å‹æœ€çµ‚èƒ½åœ¨ Kaggle ä¸Šå–å¾—è‰¯å¥½è¡¨ç¾ï¼Œæµç¨‹å®Œæ•´ä¸”å¯é‡ç¾ã€‚\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dcb1ed",
   "metadata": {},
   "source": [
    "### Read Data and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# è®€æª”ï¼ˆè·¯å¾‘ä¾ä½ çš„å¯¦éš›æƒ…æ³èª¿æ•´ï¼‰\n",
    "data_identification = pd.read_csv(\"data_identification.csv\")\n",
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "\n",
    "print(data_identification.head())\n",
    "print(emotion.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc2cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                root\n",
      "0  {'_type': 'post', '_source': {'post': {'post_i...\n",
      "1  {'_type': 'post', '_source': {'post': {'post_i...\n",
      "2  {'_type': 'post', '_source': {'post': {'post_i...\n",
      "3  {'_type': 'post', '_source': {'post': {'post_i...\n",
      "4  {'_type': 'post', '_source': {'post': {'post_i...\n",
      "Index(['root'], dtype='object')\n",
      "  _type _source.post.post_id  \\\n",
      "0  post             0x61fc95   \n",
      "1  post             0x35663e   \n",
      "2  post             0xc78afe   \n",
      "3  post             0x90089c   \n",
      "4  post             0xaba820   \n",
      "\n",
      "                                   _source.post.text _source.post.hashtags  \n",
      "0  We got the ranch, loaded our guns and sat up t...                    []  \n",
      "1  I bet there is an army of married couples who ...                    []  \n",
      "2                         This could only end badly.                    []  \n",
      "3  My sister squeezed a lime in her milk when she...                    []  \n",
      "4         and that got my head bobbing a little bit.                    []  \n",
      "Index(['_type', '_source.post.post_id', '_source.post.text',\n",
      "       '_source.post.hashtags'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# è®€ JSON\n",
    "posts = pd.read_json(\"final_posts.json\")\n",
    "print(posts.head())\n",
    "print(posts.columns)  # æ‡‰è©²åªæœ‰ä¸€å€‹ 'root'\n",
    "\n",
    "# æŠŠ root é‚£å€‹ dict å±•é–‹æˆå¤šå€‹æ¬„ä½\n",
    "posts_flat = pd.json_normalize(posts[\"root\"])\n",
    "print(posts_flat.head())\n",
    "print(posts_flat.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a518c409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text\n",
      "0  0x61fc95  We got the ranch, loaded our guns and sat up t...\n",
      "1  0x35663e  I bet there is an army of married couples who ...\n",
      "2  0xc78afe                         This could only end badly.\n",
      "3  0x90089c  My sister squeezed a lime in her milk when she...\n",
      "4  0xaba820         and that got my head bobbing a little bit.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ‘‰ é€™å…©è¡Œè«‹ä¾ä½  print å‡ºä¾†çš„æ¬„ä½åç¨±ä¿®æ”¹\n",
    "ID_COL_JSON = \"_source.post.post_id\"\n",
    "TEXT_COL_JSON = \"_source.post.text\"\n",
    "\n",
    "posts_small = posts_flat[[ID_COL_JSON, TEXT_COL_JSON]].copy()\n",
    "posts_small = posts_small.rename(columns={\n",
    "    ID_COL_JSON: \"id\",\n",
    "    TEXT_COL_JSON: \"text\"\n",
    "})\n",
    "\n",
    "print(posts_small.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c416857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  split                                               text\n",
      "0  0x61fc95   test  We got the ranch, loaded our guns and sat up t...\n",
      "1  0x35663e  train  I bet there is an army of married couples who ...\n",
      "2  0xc78afe  train                         This could only end badly.\n",
      "3  0x90089c  train  My sister squeezed a lime in her milk when she...\n",
      "4  0xaba820   test         and that got my head bobbing a little bit.\n",
      "split\n",
      "train    47890\n",
      "test     16281\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data_identification: id, split (train/test)\n",
    "df = data_identification.merge(posts_small, on=\"id\")\n",
    "print(df.head())\n",
    "print(df[\"split\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5e5a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  split                                               text emotion\n",
      "0  0x35663e  train  I bet there is an army of married couples who ...     joy\n",
      "1  0xc78afe  train                         This could only end badly.    fear\n",
      "2  0x90089c  train  My sister squeezed a lime in her milk when she...     joy\n",
      "3  0x2ffb63  train                                Thank you so muchâ¤ï¸     joy\n",
      "4  0x989146  train  Stinks because ive been in this program for a ...     joy\n",
      "         id split                                               text\n",
      "0  0x61fc95  test  We got the ranch, loaded our guns and sat up t...\n",
      "4  0xaba820  test         and that got my head bobbing a little bit.\n",
      "5  0x66e44d  test                Same. Glad it's not just out store.\n",
      "6  0xc03cf5  test  Like always i will wait and see thanks for the...\n",
      "8  0x02f65a  test  There's a bit of room between \"not loving sub-...\n",
      "Index(['id', 'split', 'text', 'emotion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# åˆ‡ train / test\n",
    "train_df = df[df[\"split\"] == \"train\"].copy()\n",
    "test_df  = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "# æŠŠ emotion æ¥åˆ° train ä¸Š\n",
    "train_df = train_df.merge(emotion, on=\"id\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6da678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text  \\\n",
      "0  0x35663e  I bet there is an army of married couples who ...   \n",
      "1  0xc78afe                         This could only end badly.   \n",
      "2  0x90089c  My sister squeezed a lime in her milk when she...   \n",
      "3  0x2ffb63                                Thank you so muchâ¤ï¸   \n",
      "4  0x989146  Stinks because ive been in this program for a ...   \n",
      "\n",
      "                                          clean_text emotion  \n",
      "0  i bet there is an army of married couples who ...     joy  \n",
      "1                          this could only end badly    fear  \n",
      "2  my sister squeezed a lime in her milk when she...     joy  \n",
      "3                                  thank you so much     joy  \n",
      "4  stinks because ive been in this program for a ...     joy  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(t):\n",
    "    t = str(t)\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
    "    t = re.sub(r\"@\\w+\", \" \", t)\n",
    "    t = re.sub(r\"#(\\w+)\", r\"\\1\", t)\n",
    "    t = re.sub(r\"<.*?>\", \" \", t)\n",
    "    t = re.sub(r\"[^\\w\\s!?]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"]  = test_df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(train_df[[\"id\", \"text\", \"clean_text\", \"emotion\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa396756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_clean.csv\", index=False)\n",
    "test_df.to_csv(\"test_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ed012",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "`build_vectorizer()` å‡½å¼ï¼ŒåŒæ™‚ç”¢ç”Ÿï¼š\n",
    "\n",
    "- **word-level TF-IDF**  \n",
    "  - n-gram: (1,1) æˆ– (1,2)  \n",
    "  - ç”¨æ–¼æ•æ‰èªæ„èˆ‡å¦å®šé—œä¿‚ï¼ˆå¦‚ â€œnot happyâ€ï¼‰\n",
    "\n",
    "- **char-level TF-IDF**  \n",
    "  - n-gram: (2,4) æˆ– (3,5)  \n",
    "  - ç‰¹åˆ¥é©åˆ noisy textï¼ˆå¦‚é‡è¤‡å­—æ¯ã€æ‹¼éŒ¯å­—ã€å¼·èª¿ç¬¦è™Ÿï¼‰\n",
    "\n",
    "ä½¿ç”¨ `FeatureUnion` å°‡å…©ç¨®ç‰¹å¾µçµåˆï¼Œæ•ˆæœæ˜é¡¯æ¯”å–®ä¸€å‘é‡å™¨æ›´ä½³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd08fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import jieba\n",
    "    _HAS_JIEBA = True\n",
    "except Exception:\n",
    "    _HAS_JIEBA = False\n",
    "\n",
    "def ensure_data():\n",
    "    # è‹¥ notebook è£¡å·²æœ‰ train_df/test_dfï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦å‰‡å˜—è©¦è®€å–å‰›å‰›å„²å­˜çš„ csv\n",
    "    global train_df, test_df\n",
    "    if 'train_df' in globals() and 'test_df' in globals():\n",
    "        return train_df, test_df\n",
    "    if os.path.exists(\"train_clean.csv\") and os.path.exists(\"test_clean.csv\"):\n",
    "        train_df = pd.read_csv(\"train_clean.csv\")\n",
    "        test_df  = pd.read_csv(\"test_clean.csv\")\n",
    "        return train_df, test_df\n",
    "    raise FileNotFoundError(\"æ‰¾ä¸åˆ° train_df/test_dfï¼Œä¹Ÿæ²’æœ‰ train_clean.csv/test_clean.csvã€‚è«‹å…ˆåŸ·è¡Œå‰é¢ cellsã€‚\")\n",
    "def build_vectorizer(use_jieba=True, word_ngram=(1,2), char_ngram=(2,4), max_word=30000, max_char=10000):\n",
    "    if use_jieba and _HAS_JIEBA:\n",
    "        tokenizer = jieba.lcut\n",
    "        word = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None, ngram_range=word_ngram, max_features=max_word)\n",
    "    else:\n",
    "        word = TfidfVectorizer(ngram_range=word_ngram, max_features=max_word)\n",
    "    char = TfidfVectorizer(analyzer='char', ngram_range=char_ngram, max_features=max_char)\n",
    "    return FeatureUnion([('word', word), ('char', char)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977caca",
   "metadata": {},
   "source": [
    "## 4. Model Development\n",
    "é€™é‚Šå˜—è©¦å¤šç¨®ä¸åŒçš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba available: False\n"
     ]
    }
   ],
   "source": [
    "def get_model(name):\n",
    "    name = name.lower()\n",
    "    if name == 'logreg':\n",
    "        return LogisticRegression(max_iter=2000, class_weight='balanced', solver='saga', multi_class='multinomial', n_jobs=-1)\n",
    "    if name == 'svc':\n",
    "        return LinearSVC(class_weight='balanced', max_iter=20000)\n",
    "    if name == 'rf':\n",
    "        return RandomForestClassifier(n_estimators=200, n_jobs=-1, class_weight='balanced')\n",
    "    # optional: xgboost / lightgbm if installed\n",
    "    try:\n",
    "        if name == 'lgbm':\n",
    "            import lightgbm as lgb\n",
    "            return lgb.LGBMClassifier(n_estimators=1000, n_jobs=-1)\n",
    "        if name == 'xgb':\n",
    "            import xgboost as xgb\n",
    "            return xgb.XGBClassifier(n_estimators=500, use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise ValueError(f\"æœªçŸ¥æ¨¡å‹ {name}\")\n",
    "\n",
    "def run_cv_and_train(model_name, vec_cfg=None, cv=5, save_model=True, out_prefix=None):\n",
    "    train_df, test_df = ensure_data()\n",
    "    X = train_df['clean_text'].astype(str)\n",
    "    y = train_df['emotion'].astype(str)\n",
    "    vec = build_vectorizer(**(vec_cfg or {}))\n",
    "    clf = get_model(model_name)\n",
    "    pipe = Pipeline([('vec', vec), ('clf', clf)])\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    print(f\"\\n---- Running CV for {model_name} ----\")\n",
    "    preds = cross_val_predict(pipe, X, y, cv=skf, n_jobs=-1)\n",
    "    print(classification_report(y, preds, digits=4))\n",
    "    macro = f1_score(y, preds, average='macro')\n",
    "    print(f\"Macro F1: {macro:.4f}\")\n",
    "    # fit on all train and predict test\n",
    "    print(\"Fitting on full train and predicting test...\")\n",
    "    pipe.fit(X, y)\n",
    "    test_X = test_df['clean_text'].astype(str)\n",
    "    test_preds = pipe.predict(test_X)\n",
    "    # prepare submission\n",
    "    sub = test_df[['id']].copy()\n",
    "    sub['emotion'] = test_preds.astype(str)\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    prefix = out_prefix or model_name\n",
    "    out_name = f\"submission_{prefix}_{timestamp}.csv\"\n",
    "    sub.to_csv(out_name, index=False, encoding='utf-8-sig')\n",
    "    print(\"Saved\", out_name)\n",
    "    if save_model:\n",
    "        model_name_file = f\"model_{prefix}_{timestamp}.joblib\"\n",
    "        joblib.dump(pipe, model_name_file)\n",
    "        print(\"Saved model to\", model_name_file)\n",
    "    return {'model': pipe, 'cv_macro_f1': macro, 'submission': out_name}\n",
    "\n",
    "\n",
    "def run_experiments(models=('logreg','svc','rf'), vec_cfg=None):\n",
    "    results = {}\n",
    "    for m in models:\n",
    "        try:\n",
    "            r = run_cv_and_train(m, vec_cfg=vec_cfg, cv=5, save_model=True, out_prefix=m)\n",
    "            results[m] = r\n",
    "        except Exception as e:\n",
    "            print(f\"Error running {m}: {e}\")\n",
    "    return results\n",
    "\n",
    "print(\"jieba available:\", _HAS_JIEBA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed673310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/19.2 MB 5.8 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 1.3/19.2 MB 4.4 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.1/19.2 MB 4.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.9/19.2 MB 3.9 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.7/19.2 MB 4.1 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.5/19.2 MB 3.9 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.0/19.2 MB 3.9 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 5.8/19.2 MB 3.8 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 6.6/19.2 MB 3.6 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 7.1/19.2 MB 3.5 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 7.9/19.2 MB 3.5 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 8.7/19.2 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.4/19.2 MB 3.5 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 10.2/19.2 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 11.0/19.2 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 11.8/19.2 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 12.6/19.2 MB 3.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.4/19.2 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.2/19.2 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 14.9/19.2 MB 3.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 15.5/19.2 MB 3.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 16.0/19.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.8/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.6/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.1/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  18.9/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 19.2/19.2 MB 3.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314474 sha256=3dbf4b68f9ef67093579646f94ae93a0975f359891d79822ae6352ba537695c8\n",
      "  Stored in directory: c:\\users\\lala9\\appdata\\local\\pip\\cache\\wheels\\8d\\e9\\51\\2f0a6a9d051293af20e265d3889beae50efe2de72f8511c801\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'jieba' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'jieba'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f72eea",
   "metadata": {},
   "source": [
    "é€™é‚Šæ˜¯å°å‡ºæ‰€æœ‰é‹è¡Œéçš„æ¨¡å‹çš„çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdf4d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Running CV for logreg ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.4607    0.5600    0.5055     10694\n",
      "     disgust     0.1009    0.1809    0.1295      1183\n",
      "        fear     0.2765    0.5032    0.3569      2009\n",
      "         joy     0.8318    0.5960    0.6944     23797\n",
      "     sadness     0.3197    0.3930    0.3526      3926\n",
      "    surprise     0.4412    0.5080    0.4723      6281\n",
      "\n",
      "    accuracy                         0.5457     47890\n",
      "   macro avg     0.4051    0.4569    0.4185     47890\n",
      "weighted avg     0.6143    0.5457    0.5670     47890\n",
      "\n",
      "Macro F1: 0.4185\n",
      "Fitting on full train and predicting test...\n",
      "Saved submission_logreg_20251124-160646.csv\n",
      "Saved model to model_logreg_20251124-160646.joblib\n",
      "\n",
      "---- Running CV for svc ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5254    0.5218    0.5236     10694\n",
      "     disgust     0.1734    0.1445    0.1577      1183\n",
      "        fear     0.4037    0.4425    0.4222      2009\n",
      "         joy     0.7592    0.7351    0.7470     23797\n",
      "     sadness     0.3275    0.3500    0.3384      3926\n",
      "    surprise     0.4407    0.4802    0.4596      6281\n",
      "\n",
      "    accuracy                         0.5956     47890\n",
      "   macro avg     0.4383    0.4457    0.4414     47890\n",
      "weighted avg     0.6004    0.5956    0.5977     47890\n",
      "\n",
      "Macro F1: 0.4414\n",
      "Fitting on full train and predicting test...\n",
      "Saved submission_svc_20251124-160831.csv\n",
      "Saved model to model_svc_20251124-160831.joblib\n",
      "\n",
      "---- Running CV for rf ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5910    0.2544    0.3557     10694\n",
      "     disgust     0.4541    0.0710    0.1228      1183\n",
      "        fear     0.5804    0.2245    0.3238      2009\n",
      "         joy     0.5683    0.9390    0.7080     23797\n",
      "     sadness     0.5910    0.1480    0.2367      3926\n",
      "    surprise     0.6084    0.1957    0.2961      6281\n",
      "\n",
      "    accuracy                         0.5724     47890\n",
      "   macro avg     0.5655    0.3054    0.3405     47890\n",
      "weighted avg     0.5782    0.5724    0.5061     47890\n",
      "\n",
      "Macro F1: 0.3405\n",
      "Fitting on full train and predicting test...\n",
      "Saved submission_rf_20251124-162252.csv\n",
      "Saved model to model_rf_20251124-162252.joblib\n",
      "{'logreg': {'model': Pipeline(steps=[('vec',\n",
      "                 FeatureUnion(transformer_list=[('word',\n",
      "                                                 TfidfVectorizer(max_features=30000,\n",
      "                                                                 ngram_range=(1,\n",
      "                                                                              2))),\n",
      "                                                ('char',\n",
      "                                                 TfidfVectorizer(analyzer='char',\n",
      "                                                                 max_features=10000,\n",
      "                                                                 ngram_range=(2,\n",
      "                                                                              4)))])),\n",
      "                ('clf',\n",
      "                 LogisticRegression(class_weight='balanced', max_iter=2000,\n",
      "                                    multi_class='multinomial', n_jobs=-1,\n",
      "                                    solver='saga'))]), 'cv_macro_f1': 0.4185449695375969, 'submission': 'submission_logreg_20251124-160646.csv'}, 'svc': {'model': Pipeline(steps=[('vec',\n",
      "                 FeatureUnion(transformer_list=[('word',\n",
      "                                                 TfidfVectorizer(max_features=30000,\n",
      "                                                                 ngram_range=(1,\n",
      "                                                                              2))),\n",
      "                                                ('char',\n",
      "                                                 TfidfVectorizer(analyzer='char',\n",
      "                                                                 max_features=10000,\n",
      "                                                                 ngram_range=(2,\n",
      "                                                                              4)))])),\n",
      "                ('clf', LinearSVC(class_weight='balanced', max_iter=20000))]), 'cv_macro_f1': 0.4414057813550916, 'submission': 'submission_svc_20251124-160831.csv'}, 'rf': {'model': Pipeline(steps=[('vec',\n",
      "                 FeatureUnion(transformer_list=[('word',\n",
      "                                                 TfidfVectorizer(max_features=30000,\n",
      "                                                                 ngram_range=(1,\n",
      "                                                                              2))),\n",
      "                                                ('char',\n",
      "                                                 TfidfVectorizer(analyzer='char',\n",
      "                                                                 max_features=10000,\n",
      "                                                                 ngram_range=(2,\n",
      "                                                                              4)))])),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(class_weight='balanced',\n",
      "                                        n_estimators=200, n_jobs=-1))]), 'cv_macro_f1': 0.34052622658575765, 'submission': 'submission_rf_20251124-162252.csv'}}\n"
     ]
    }
   ],
   "source": [
    "results = run_experiments(models=('logreg','svc','rf'), vec_cfg={'use_jieba':True, 'word_ngram':(1,2), 'char_ngram':(2,4)})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b3a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross_val_predict for SVC ...\n",
      "CV classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5254    0.5218    0.5236     10694\n",
      "     disgust     0.1734    0.1445    0.1577      1183\n",
      "        fear     0.4037    0.4425    0.4222      2009\n",
      "         joy     0.7592    0.7351    0.7470     23797\n",
      "     sadness     0.3275    0.3500    0.3384      3926\n",
      "    surprise     0.4407    0.4802    0.4596      6281\n",
      "\n",
      "    accuracy                         0.5956     47890\n",
      "   macro avg     0.4383    0.4457    0.4414     47890\n",
      "weighted avg     0.6004    0.5956    0.5977     47890\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "          anger  disgust  fear    joy  sadness  surprise\n",
      "anger      5580      331   372   2303      903      1205\n",
      "disgust     410      171    94    256      145       107\n",
      "fear        304       56   889    409      187       164\n",
      "joy        2468      237   523  17494     1157      1918\n",
      "sadness     845      118   187    968     1374       434\n",
      "surprise   1013       73   137   1613      429      3016\n",
      "Full-train predicted label counts (submission):\n",
      "joy         7207\n",
      "anger       3936\n",
      "surprise    2140\n",
      "sadness     1467\n",
      "fear        1147\n",
      "disgust      384\n",
      "Name: count, dtype: int64\n",
      "Train CV predicted label counts:\n",
      "joy         23043\n",
      "anger       10620\n",
      "surprise     6844\n",
      "sadness      4195\n",
      "fear         2202\n",
      "disgust       986\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Trying CalibratedClassifierCV (3-fold) ...\n",
      "Calibrated CV classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5482    0.5147    0.5309     10694\n",
      "     disgust     0.5957    0.0237    0.0455      1183\n",
      "        fear     0.5919    0.2678    0.3687      2009\n",
      "         joy     0.6586    0.8876    0.7561     23797\n",
      "     sadness     0.5726    0.1798    0.2737      3926\n",
      "    surprise     0.5694    0.3253    0.4140      6281\n",
      "\n",
      "    accuracy                         0.6252     47890\n",
      "   macro avg     0.5894    0.3665    0.3982     47890\n",
      "weighted avg     0.6108    0.6252    0.5876     47890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic cellï¼šæ¯”è¼ƒ CV èˆ‡ full-train submissionï¼Œä¸¦å˜—è©¦ Calibrated SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df, test_df = ensure_data()\n",
    "X = train_df['clean_text'].astype(str)\n",
    "y = train_df['emotion'].astype(str)\n",
    "\n",
    "# build SVC pipeline (èˆ‡ä½ ä¹‹å‰ run_experiments ä¸­ç›¸åŒè¨­å®š)\n",
    "vec = build_vectorizer(use_jieba=False, word_ngram=(1,2), char_ngram=(2,4))\n",
    "svc = get_model('svc')  # LinearSVC\n",
    "pipe = Pipeline([('vec', vec), ('clf', svc)])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 1) CV é æ¸¬èˆ‡å ±å‘Š\n",
    "print(\"Running cross_val_predict for SVC ...\")\n",
    "preds_cv = cross_val_predict(pipe, X, y, cv=skf, n_jobs=-1)\n",
    "print(\"CV classification report:\")\n",
    "print(classification_report(y, preds_cv, digits=4))\n",
    "\n",
    "# 2) Confusion matrix (æ›´ç›´è§€åœ°çœ‹å“ªäº› class è¢«èª¤åˆ†é¡)\n",
    "cm = confusion_matrix(y, preds_cv, labels=np.unique(y))\n",
    "cm_df = pd.DataFrame(cm, index=np.unique(y), columns=np.unique(y))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(cm_df)\n",
    "\n",
    "# 3) Fit on full train and predict test (å°±æ˜¯ä½ æäº¤çš„æµç¨‹)\n",
    "pipe.fit(X, y)\n",
    "test_preds_full = pipe.predict(test_df['clean_text'].astype(str))\n",
    "print(\"Full-train predicted label counts (submission):\")\n",
    "print(pd.Series(test_preds_full).value_counts())\n",
    "\n",
    "# 4) æ¯”è¼ƒ CV é æ¸¬åˆ†ä½ˆèˆ‡ full-train é æ¸¬åˆ†ä½ˆ\n",
    "print(\"Train CV predicted label counts:\")\n",
    "print(pd.Series(preds_cv).value_counts())\n",
    "\n",
    "# 5) å˜—è©¦ Calibrationï¼ˆè‹¥ SVC çš„ decision boundary å°å°‘æ•¸é¡ä¸å¥½ï¼Œcalibration æœ‰æ™‚æœ‰å¹«åŠ©ï¼‰\n",
    "print(\"\\nTrying CalibratedClassifierCV (3-fold) ...\")\n",
    "calibrated_clf = CalibratedClassifierCV(svc, cv=3)  # å…§éƒ¨æœƒåš calibrate\n",
    "pipe_cal = Pipeline([('vec', vec), ('clf', calibrated_clf)])\n",
    "preds_cv_cal = cross_val_predict(pipe_cal, X, y, cv=skf, n_jobs=-1, method='predict')\n",
    "print(\"Calibrated CV classification report:\")\n",
    "print(classification_report(y, preds_cv_cal, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfd560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.4954    0.4985    0.4969     10694\n",
      "     disgust     0.1544    0.1336    0.1432      1183\n",
      "        fear     0.3863    0.4126    0.3990      2009\n",
      "         joy     0.7482    0.7066    0.7268     23797\n",
      "     sadness     0.3051    0.3334    0.3186      3926\n",
      "    surprise     0.3919    0.4488    0.4184      6281\n",
      "\n",
      "    accuracy                         0.5692     47890\n",
      "   macro avg     0.4135    0.4223    0.4172     47890\n",
      "weighted avg     0.5788    0.5692    0.5734     47890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imbalanced sampling in CV (éœ€è¦ pip install imbalanced-learn)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "\n",
    "vec = build_vectorizer(use_jieba=False, word_ngram=(1,2), char_ngram=(3,5))\n",
    "svc = get_model('svc')\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "pipe = ImbPipeline([('vec', vec), ('ros', ros), ('clf', svc)])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "preds = cross_val_predict(pipe, train_df['clean_text'], train_df['emotion'], cv=skf, n_jobs=-1)\n",
    "print(classification_report(train_df['emotion'], preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb159e",
   "metadata": {},
   "source": [
    "### Hyparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "0.4750706205526359 {'clf__C': 0.1, 'vec__char__ngram_range': (2, 4), 'vec__word__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vec', build_vectorizer(use_jieba=False)), ('clf', get_model('svc'))])\n",
    "params = {\n",
    "  'vec__word__ngram_range': [(1,1),(1,2)],\n",
    "  'vec__char__ngram_range': [(2,4),(3,5)],\n",
    "  'clf__C': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "gs = GridSearchCV(pipe, params, cv=StratifiedKFold(5), scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "gs.fit(train_df['clean_text'], train_df['emotion'])\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06cfdef",
   "metadata": {},
   "source": [
    "### Additional Experimentsï¼ˆBonusï¼‰\n",
    "- Stacking Ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c7220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.5637    0.4510    0.5011     10694\n",
      "     disgust     0.0937    0.2375    0.1344      1183\n",
      "        fear     0.3920    0.4400    0.4146      2009\n",
      "         joy     0.7429    0.7673    0.7549     23797\n",
      "     sadness     0.3741    0.3655    0.3698      3926\n",
      "    surprise     0.5008    0.4517    0.4750      6281\n",
      "\n",
      "    accuracy                         0.5955     47890\n",
      "   macro avg     0.4445    0.4522    0.4416     47890\n",
      "weighted avg     0.6101    0.5955    0.6003     47890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "svc = CalibratedClassifierCV(get_model('svc'), cv=3)\n",
    "logreg = get_model('logreg')\n",
    "pipe_svc = Pipeline([('vec', build_vectorizer(use_jieba=False)), ('clf', svc)])\n",
    "pipe_log = Pipeline([('vec', build_vectorizer(use_jieba=False)), ('clf', logreg)])\n",
    "\n",
    "# ç›´æ¥åœ¨å‘é‡åŒ–å¾Œ ensembleï¼ˆç¤ºæ„ï¼Œå¯¦éš›å»ºè­°ç”¨å–®ä¸€ vec å† ensemble clfï¼‰\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "v = VotingClassifier(estimators=[('svc', svc), ('log', logreg)], voting='soft')\n",
    "pipe_vote = Pipeline([('vec', build_vectorizer(use_jieba=True)), ('clf', v)])\n",
    "# CV è©•ä¼°\n",
    "preds = cross_val_predict(pipe_vote, train_df['clean_text'], train_df['emotion'], cv=5, n_jobs=-1)\n",
    "print(classification_report(train_df['emotion'], preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best (f1_macro): 0.4750706205526359\n",
      "Best params: {'clf__C': 0.1, 'vec__char__ngram_range': (2, 4), 'vec__word__ngram_range': (1, 2)}\n",
      "Saved submission_gs_best.csv\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# ä½¿ç”¨ GridSearchCV çš„æœ€ä½³æ¨¡å‹ç”¢ç”Ÿ submission\n",
    "best_score = gs.best_score_\n",
    "best_params = gs.best_params_\n",
    "print(\"CV best (f1_macro):\", best_score)\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "best_model = gs.best_estimator_  # å·² refit åœ¨å…¨éƒ¨ training ä¸Š (é è¨­ refit=True)\n",
    "\n",
    "\n",
    "test_preds = best_model.predict(test_df['clean_text'].astype(str))\n",
    "submission = test_df[['id']].copy()\n",
    "submission['emotion'] = test_preds\n",
    "submission.to_csv('submission_gs_best.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved submission_gs_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18460db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking CV macro F1: 0.45830663718753684\n",
      "Saved submission_stack.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "train_df, test_df = ensure_data()\n",
    "X = train_df['clean_text'].astype(str)\n",
    "y = train_df['emotion'].astype(str)\n",
    "test_X = test_df['clean_text'].astype(str)\n",
    "\n",
    "vec = build_vectorizer(use_jieba=True, word_ngram=(1,2), char_ngram=(2,4))\n",
    "\n",
    "# base models (svc è¦ calibrate æ‰èƒ½ output probs)\n",
    "svc = CalibratedClassifierCV(get_model('svc'), cv=3)\n",
    "logr = get_model('logreg')\n",
    "rf   = get_model('rf')\n",
    "\n",
    "base_models = [('svc', svc), ('logr', logr), ('rf', rf)]\n",
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF probs\n",
    "oof_train = np.zeros((len(X), len(np.unique(y))*len(base_models))) \n",
    "oof_test  = np.zeros((len(test_X), len(np.unique(y))*len(base_models)))\n",
    "\n",
    "for i,(name,model) in enumerate(base_models):\n",
    "    oof_p = np.zeros((len(X), len(np.unique(y))))\n",
    "    test_p = np.zeros((len(test_X), len(np.unique(y)), K))\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_tr = vec.fit_transform(X.iloc[tr_idx])\n",
    "        X_val = vec.transform(X.iloc[val_idx])\n",
    "        model.fit(X_tr, y.iloc[tr_idx])\n",
    "        oof_p[val_idx] = model.predict_proba(X_val)\n",
    "        test_p[:,:,fold] = model.predict_proba(vec.transform(test_X))\n",
    "    oof_train[:, i*len(np.unique(y)):(i+1)*len(np.unique(y))] = oof_p\n",
    "    oof_test[:, i*len(np.unique(y)):(i+1)*len(np.unique(y))]  = test_p.mean(axis=2)\n",
    "\n",
    "# meta classifier\n",
    "meta = LogisticRegression(max_iter=2000, multi_class='multinomial', class_weight='balanced')\n",
    "meta.fit(oof_train, y)\n",
    "meta_preds = meta.predict(oof_train)\n",
    "print(\"Stacking CV macro F1:\", f1_score(y, meta_preds, average='macro'))\n",
    "\n",
    "# predict test and save submission\n",
    "final_preds = meta.predict(oof_test)\n",
    "sub = test_df[['id']].copy()\n",
    "sub['emotion'] = final_preds\n",
    "sub.to_csv('submission_stack.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved submission_stack.csv\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fee38",
   "metadata": {},
   "source": [
    "#### ä¸‹é¢æ˜¯Stackçš„å¾®èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6988afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "def build_vectorizer(word_ngram=(1,2),\n",
    "                     char_ngram=(3,5),\n",
    "                     max_word=60000,\n",
    "                     max_char=20000,\n",
    "                     sublinear_tf=True):\n",
    "\n",
    "    word = TfidfVectorizer(\n",
    "        ngram_range=word_ngram,\n",
    "        max_features=max_word,\n",
    "        sublinear_tf=sublinear_tf\n",
    "    )\n",
    "\n",
    "    char = TfidfVectorizer(\n",
    "        analyzer='char',\n",
    "        ngram_range=char_ngram,\n",
    "        max_features=max_char,\n",
    "        sublinear_tf=sublinear_tf\n",
    "    )\n",
    "\n",
    "    return FeatureUnion([\n",
    "        ('word', word),\n",
    "        ('char', char)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "154b5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "\n",
    "    # word-level TF-IDF\n",
    "    'vec__word__ngram_range': [(1,1), (1,2)],\n",
    "    'vec__word__max_features': [30000, 60000],\n",
    "\n",
    "    # char-level TF-IDF\n",
    "    'vec__char__ngram_range': [(2,4), (3,5)],\n",
    "    'vec__char__max_features': [20000, 40000],\n",
    "\n",
    "    # shared\n",
    "    'vec__word__sublinear_tf': [True],\n",
    "    'vec__char__sublinear_tf': [True],\n",
    "\n",
    "    # SVC\n",
    "    'clf__C': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed6d2a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best CV Score: nan\n",
      "Best Params: {'clf__C': 0.1, 'vec__char__max_features': 20000, 'vec__char__ngram_range': (2, 4), 'vec__char__sublinear_tf': True, 'vec__word__max_features': 30000, 'vec__word__ngram_range': (1, 1), 'vec__word__sublinear_tf': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(train_df['clean_text'], train_df['emotion'])\n",
    "\n",
    "print(\"Best CV Score:\", grid.best_score_)\n",
    "print(\"Best Params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53389bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_gs_best_tuned.csv\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "\n",
    "test_preds = best_model.predict(test_df['clean_text'].astype(str))\n",
    "submission = test_df[['id']].copy()\n",
    "submission['emotion'] = test_preds\n",
    "\n",
    "submission.to_csv(\"submission_gs_best_tuned.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved submission_gs_best_tuned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
